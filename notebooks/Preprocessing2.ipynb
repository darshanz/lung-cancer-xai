{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6e1d9a8-a44d-4265-8516-2ff6d331835c",
   "metadata": {},
   "source": [
    "# DICOM slices to torch tensors\n",
    "- Converting the DICOM slices into torch tensors and save the CT Volumes in different folder\n",
    "- Window the image based on the window information in the dicom slice\n",
    "- The window information is same for all the slices. So replaced with the common value if the information is missing in the dicom file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f822c10-8df8-482b-bdb0-fcf4bcf37a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pydicom import dcmread\n",
    "from pydicom import multival\n",
    "import os\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "import SimpleITK as sitk\n",
    "from einops import rearrange\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import torch\n",
    "\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "413aa18f-c27e-4e96-a2d3-d84705845358",
   "metadata": {},
   "outputs": [],
   "source": [
    "CT_Slice_DIR = \"/Users/sudarshan/darshanz/datasets/lung1/CT_ONLY/slices\"\n",
    "CT_Vol_DIR = \"/Users/sudarshan/darshanz/datasets/lung1/CT_ONLY/vols\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee292f6e-49cd-4b57-86d4-22310931787d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to take care of teh translation and windowing. \n",
    "def window_image(img, window_center,window_width, intercept, slope, rescale=True):\n",
    "    img = (img*slope +intercept) #for translation adjustments given in the dicom file. \n",
    "    img_min = window_center - window_width//2 #minimum HU level\n",
    "    img_max = window_center + window_width//2 #maximum HU level\n",
    "    img[img<img_min] = img_min #set img_min for all HU levels less than minimum HU level\n",
    "    img[img>img_max] = img_max #set img_max for all HU levels higher than maximum HU level\n",
    "    if rescale: \n",
    "        img = (img - img_min) / (img_max - img_min)*255.0 \n",
    "    img_resized = resize(img, (224, 224))\n",
    "    return img_resized\n",
    "\n",
    "def get_first_of_dicom_field_as_int(x):\n",
    "    #get x[0] as in int is x is a 'pydicom.multival.MultiValue', otherwise get int(x)\n",
    "    if type(x) == multival.MultiValue: return int(x[0])\n",
    "    else: return int(x)\n",
    "    \n",
    "def get_windowing(data):\n",
    "    dicom_fields = [data[('0028','1050')].value, #window center\n",
    "                    data[('0028','1051')].value, #window width\n",
    "                    data[('0028','1052')].value, #intercept\n",
    "                    data[('0028','1053')].value] #slope\n",
    "    return [get_first_of_dicom_field_as_int(x) for x in dicom_fields]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a572e73-9fe0-4a34-a664-5b918a87620f",
   "metadata": {},
   "source": [
    "#### iterate through all subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01507005-ec9c-42ee-acfb-2626a4f5249e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 423/423 [04:49<00:00,  1.46it/s]\n"
     ]
    }
   ],
   "source": [
    "for subject_ in tqdm(sorted(os.listdir(CT_Slice_DIR))):\n",
    "    if subject_ not in '.DS_Store':\n",
    "        #check slices\n",
    "        ls_vol = []\n",
    "        slices = os.listdir(f'{CT_Slice_DIR}/{subject_}')\n",
    "        for dcm_file in sorted(slices):\n",
    "            data = dcmread(f\"{CT_Slice_DIR}/{subject_}/{dcm_file}\")\n",
    "            try:\n",
    "                window_center , window_width, intercept, slope = get_windowing(data)  \n",
    "            except:\n",
    "                window_center , window_width, intercept, slope = 40, 400, -1024, 1\n",
    "            output = window_image(data.pixel_array, window_center, window_width, intercept, slope, rescale = False)\n",
    "            ls_vol.append(output)\n",
    "\n",
    "        torch.save(torch.tensor(np.array(ls_vol), dtype=torch.float64), f\"{CT_Vol_DIR}/{subject_}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f32152d-16d1-422e-853a-5cf71f9d44ea",
   "metadata": {},
   "source": [
    "### make number of slices equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76e7658b-d184-46c8-90c5-691e01b35533",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 423/423 [00:12<00:00, 34.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "slice_counts = []\n",
    "for subject_ in tqdm(sorted(os.listdir(CT_Vol_DIR))):\n",
    "    if subject_ not in '.DS_Store':\n",
    "        ct = torch.load(f'{CT_Vol_DIR}/{subject_}')\n",
    "        slice_counts.append(ct.shape[0])\n",
    "print(max(slice_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c94a8ef4-9f61-4f10-8646-6cafcae44b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 423/423 [00:15<00:00, 27.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cv_volume\n",
    "slice_counts_new = []\n",
    "for subject_ in tqdm(sorted(os.listdir(CT_Vol_DIR))):\n",
    "    if subject_ not in '.DS_Store':\n",
    "        ct = torch.load(f'{CT_Vol_DIR}/{subject_}')\n",
    "        ct_resized = torch.cat((ct, torch.zeros(300 - ct.size(0), 224, 224)), dim=0)\n",
    "        slice_counts_new.append(ct_resized.shape[0])\n",
    "        cv_volume = ct_resized\n",
    "print(max(slice_counts_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82dac156-0530-453f-9923-6be042efac45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300, 224, 224])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct_resized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd6cb892-ffdb-4212-969b-b79ea5af36a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e83048188ee4888ae7cda0a569e69be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='slice_num', max=299), Output()), _dom_classes=('widget-i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_func(slice_num, img_)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_func(slice_num, img_):\n",
    "    plt.imshow(img_[slice_num], plt.cm.gray)\n",
    "\n",
    "interact(plot_func, slice_num = widgets.IntSlider(value=1, min=0,  max=299, step=1), img_=widgets.fixed(ct_resized))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d2fe71-443c-41e4-802c-22058b093874",
   "metadata": {},
   "source": [
    "### Save the resized volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48efdc33-d744-40c1-8c82-806cecf17ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 423/423 [01:22<00:00,  5.13it/s]\n"
     ]
    }
   ],
   "source": [
    "for subject_ in tqdm(sorted(os.listdir(CT_Vol_DIR))):\n",
    "    if subject_ not in '.DS_Store':\n",
    "        ct = torch.load(f'{CT_Vol_DIR}/{subject_}')\n",
    "        ct_resized = torch.cat((ct, torch.zeros(300 - ct.size(0), 224, 224)), dim=0)\n",
    "        torch.save(ct_resized, f'{CT_Vol_DIR}/{subject_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb87b6e-f34e-4ca4-87d0-5efb0791dbae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
